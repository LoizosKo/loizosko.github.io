{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Python\n",
    "\n",
    "## Outline / Steps to do the analysis\n",
    "\n",
    "* Load the necessary packages into memory\n",
    "* Use the \"official classification\" and create the labels for personality traits for every person in the dataset\n",
    "* Train the models to be able to identify personalities of new individuals using:\n",
    "    * Knn\n",
    "    * Simple Tree\n",
    "    * Random Forest\n",
    "    * XGBoost\n",
    "    * SVM\n",
    "    \n",
    "* Run classification for Alex's personality using the above-mentioned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading in modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 125</th>\n",
       "      <th>Unnamed: 126</th>\n",
       "      <th>Unnamed: 127</th>\n",
       "      <th>Unnamed: 128</th>\n",
       "      <th>Unnamed: 129</th>\n",
       "      <th>Unnamed: 130</th>\n",
       "      <th>Unnamed: 131</th>\n",
       "      <th>Unnamed: 132</th>\n",
       "      <th>Unnamed: 133</th>\n",
       "      <th>Unnamed: 134</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/20/20 12:35</td>\n",
       "      <td>2/20/20 12:35</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/20 12:35</td>\n",
       "      <td>preview</td>\n",
       "      <td>EN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2/20/20 15:13</td>\n",
       "      <td>2/20/20 15:24</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/20 15:24</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2/20/20 15:16</td>\n",
       "      <td>2/20/20 15:24</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/20 15:24</td>\n",
       "      <td>qr</td>\n",
       "      <td>EN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2/20/20 15:13</td>\n",
       "      <td>2/20/20 15:25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/20 15:25</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2/20/20 15:16</td>\n",
       "      <td>2/20/20 15:25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>2/20/20 15:25</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5  \\\n",
       "4  2/20/20 12:35  2/20/20 12:35          1        100         36          1   \n",
       "5  2/20/20 15:13  2/20/20 15:24          0        100        648          1   \n",
       "6  2/20/20 15:16  2/20/20 15:24          0        100        495          1   \n",
       "7  2/20/20 15:13  2/20/20 15:25          0        100        718          1   \n",
       "8  2/20/20 15:16  2/20/20 15:25          0        100        580          1   \n",
       "\n",
       "      Unnamed: 6 Unnamed: 7 Unnamed: 8  X10  ... Unnamed: 125 Unnamed: 126  \\\n",
       "4  2/20/20 12:35    preview         EN  NaN  ...          NaN          NaN   \n",
       "5  2/20/20 15:24  anonymous         EN    3  ...            2            1   \n",
       "6  2/20/20 15:24         qr         EN    4  ...            1            2   \n",
       "7  2/20/20 15:25  anonymous         EN    4  ...            2            2   \n",
       "8  2/20/20 15:25  anonymous         EN    2  ...            2            2   \n",
       "\n",
       "  Unnamed: 127 Unnamed: 128 Unnamed: 129 Unnamed: 130 Unnamed: 131  \\\n",
       "4          NaN          NaN          NaN          NaN            2   \n",
       "5            1            2            2           32            2   \n",
       "6            1            1            1           22            2   \n",
       "7            2            2            2           23            1   \n",
       "8            2            1            2           30            2   \n",
       "\n",
       "  Unnamed: 132 Unnamed: 133 Unnamed: 134  \n",
       "4            2            3          NaN  \n",
       "5            1          NaN          NaN  \n",
       "6            1          NaN          NaN  \n",
       "7            1          NaN          NaN  \n",
       "8            1          NaN          NaN  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>...</th>\n",
       "      <th>Q116</th>\n",
       "      <th>Q117</th>\n",
       "      <th>Q118</th>\n",
       "      <th>Q119</th>\n",
       "      <th>Q120</th>\n",
       "      <th>Q121</th>\n",
       "      <th>Q122</th>\n",
       "      <th>Q123</th>\n",
       "      <th>Q124</th>\n",
       "      <th>Q125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q4  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  ...  Q116  Q117  Q118  Q119  \\\n",
       "0   2   1   2   5   4   2    4    5    1    1  ...     1     1     1     2   \n",
       "\n",
       "   Q120  Q121  Q122  Q123  Q124  Q125  \n",
       "0     2     2     1     1     1     1  \n",
       "\n",
       "[1 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following two lines change the way\n",
    "# the notebook is displayed\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# Now we load the important functions\n",
    "import pandas as pd #For working with dataframes\n",
    "import numpy as np #For working with arrays, pandas is built on top of this --> makes things look nicer.\n",
    "from pprint import pprint #For printing things nicely\n",
    "import matplotlib.pyplot as plt #For plotting\n",
    "import seaborn as sns\n",
    "\n",
    "# Now we can load the data\n",
    "class_df = pd.read_csv('personality_tests.csv').iloc[4:,] #'iloc' pulls rows starting at row 4 (which is actually the 5th row since here everything starts from 0)\n",
    "alex_df = pd.read_csv('alexahpenev_personality.csv')\n",
    "display(class_df.head()) #head ==> the first 5 rows\n",
    "display(alex_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate our class data into two datasets. One for Big Five questions and one for MBTI. We'll convert all of the columns to numeric fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Q1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Q1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/71/m9n1tm292gg25xn0m44ccvxh0000gn/T/ipykernel_91830/3074414018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# one for Big5 and one for MBTI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbigfive_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Q1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Q54'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#'.loc' ==> seperate bigfive // '.copy' ==> we create a copy of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmbti_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Q55'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Q125'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#':,' means to take every single note\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmbti_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Q59'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#I choose to drop Q59 because is the same question as the Q60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   5683\u001b[0m         \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5684\u001b[0m         \"\"\"\n\u001b[0;32m-> 5685\u001b[0;31m         \u001b[0mstart_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5687\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   5885\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5887\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5889\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5807\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5799\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5800\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5801\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5802\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Q1'"
     ]
    }
   ],
   "source": [
    "# We separate the data into two separate questionnaires, \n",
    "# one for Big5 and one for MBTI\n",
    "\n",
    "bigfive_df = class_df.copy().loc[:,'Q1':'Q54'] #'.loc' ==> seperate bigfive // '.copy' ==> we create a copy of the dataset\n",
    "mbti_df = class_df.copy().loc[:,'Q55':'Q125'] #':,' means to take every single note \n",
    "mbti_df.drop(labels= 'Q59', axis=1, inplace=True) #I choose to drop Q59 because is the same question as the Q60\n",
    "\n",
    "#The \"loc\" function allows us to look up rows/columns by name \n",
    "#\"iloc\" let's us look up rows/columns by index\n",
    "\n",
    "bigfive_df = bigfive_df.apply(pd.to_numeric, axis=1)\n",
    "mbti_df = mbti_df.apply(pd.to_numeric, axis=1)\n",
    "\n",
    "print('Big Five Dimensions Before Dropping {}'.format(bigfive_df.shape))\n",
    "bigfive_df.dropna(how='any', inplace=True)#we drop 'na'. // 'inplace= True' ovewrites the original dataset.\n",
    "print('Big Five Dimensions After Dropping {}'.format(bigfive_df.shape))\n",
    "\n",
    "print('MBTI Dimensions Before Dropping {}'.format(mbti_df.shape))\n",
    "mbti_df.dropna(how='any', inplace=True)\n",
    "print('MBTI Dimensions After Dropping {}'.format(mbti_df.shape))\n",
    "\n",
    "display(bigfive_df)\n",
    "display(mbti_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this chunk, I will use the provided formulas to calculate\n",
    "# personality traits. This is different from letting the data\n",
    "# speak for itself, hence why it is called supervised learning\n",
    "\n",
    "\n",
    "bigfive_df['E'] = 20 + bigfive_df[['Q1','Q14','Q24','Q34','Q45']].sum(axis=1) - bigfive_df[['Q9','Q19','Q29','Q39','Q50']].sum(axis=1)\n",
    "bigfive_df['A'] = 14 + bigfive_df[['Q10','Q20','Q30','Q40','Q46','Q51']].sum(axis=1) - bigfive_df[['Q4','Q15','Q25','Q35']].sum(axis=1)\n",
    "bigfive_df['C'] = 14 + bigfive_df[['Q6','Q16','Q26','Q36','Q47','Q52']].sum(axis=1) - bigfive_df[['Q11','Q21','Q31','Q41','Q52']].sum(axis=1)\n",
    "bigfive_df['N'] = 38 + bigfive_df[['Q12','Q22']].sum(axis=1) - bigfive_df[['Q7','Q17','Q27','Q32','Q37','Q42','Q48','Q53']].sum(axis=1)\n",
    "bigfive_df['O'] = 8 + bigfive_df[['Q8','Q18','Q28','Q38','Q43','Q49','Q54']].sum(axis=1) - bigfive_df[['Q13','Q23','Q33']].sum(axis=1)\n",
    "\n",
    "#Let's look at the summary statistics for Extroversion\n",
    "display(bigfive_df['E'].describe())\n",
    "\n",
    "#Create a boolean field that indicates whether the subject is extroverted based on the 50% cutoff\n",
    "bigfive_df['is_extroverted'] = bigfive_df['E'].apply(lambda x: 1 if x >= 24 else 0)\n",
    "display(bigfive_df.head())\n",
    "\n",
    "#Do the same for alex\n",
    "alex_df['E'] = 20 + alex_df[['Q1','Q14','Q24','Q34','Q45']].sum(axis=1) - alex_df[['Q9','Q19','Q29','Q39','Q50']].sum(axis=1)\n",
    "alex_df['A'] = 14 + alex_df[['Q10','Q20','Q30','Q40','Q46','Q51']].sum(axis=1) - alex_df[['Q4','Q15','Q25','Q35']].sum(axis=1)\n",
    "alex_df['C'] = 14 + alex_df[['Q6','Q16','Q26','Q36','Q47','Q52']].sum(axis=1) - alex_df[['Q11','Q21','Q31','Q41','Q52']].sum(axis=1)\n",
    "alex_df['N'] = 38 + alex_df[['Q12','Q22']].sum(axis=1) - alex_df[['Q7','Q17','Q27','Q32','Q37','Q42','Q48','Q53']].sum(axis=1)\n",
    "alex_df['O'] = 8 + alex_df[['Q8','Q18','Q28','Q38','Q43','Q49','Q54']].sum(axis=1) - alex_df[['Q13','Q23','Q33']].sum(axis=1)\n",
    "\n",
    "alex_df['is_extroverted'] = alex_df['E'].apply(lambda x: 1 if x >= 24 else 0)#'lambda' function does something specific (7:57 pm, 3 Mar)\n",
    "\n",
    "display(alex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to split our data into a train set and a test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bf_features = bigfive_df.loc[:,'Q1':'Q54']\n",
    "bf_target = bigfive_df['is_extroverted']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(bf_features, bf_target, test_size = 0.2, random_state = 42) \n",
    "#this command requires several arguments. bf_features list all the questions. bf_target is the dependent variable (aka in this case, whether someone is extroverted or not)\n",
    "#this command returns four things (in R you can only return one) --> train dataset, test for that dataset, train..., test...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we apply the Knn algorithm on a range of different k's.\n",
    "# This way we can see which K is the best for our data.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "\n",
    "max_neighbors = 10\n",
    "\n",
    "k_outputs = {\n",
    "    'k' : [],\n",
    "    'accuracy_score_raw' : [],\n",
    "    'accuracy_score' : []\n",
    "}\n",
    "\n",
    "for num_neighbors in range(1, max_neighbors+1):\n",
    "    knn_model = knn(n_neighbors = num_neighbors)\n",
    "    knn_model.fit(x_train, y_train)#'x_train' all variables, 'y_train' all outcomes\n",
    "    test_predictions = knn_model.predict(x_test)\n",
    "    accuracy_score_raw = knn_model.score(x_test, y_test)\n",
    "    accuracy_score = \"{:.2%}\".format(accuracy_score_raw)\n",
    "    k_outputs['k'].append(num_neighbors)\n",
    "    k_outputs['accuracy_score'].append(accuracy_score)\n",
    "    k_outputs['accuracy_score_raw'].append(accuracy_score_raw)\n",
    "    \n",
    "k_selection_df = pd.DataFrame(k_outputs)\n",
    "\n",
    "display(k_selection_df)\n",
    "k_selection_df.plot(x='k', y='accuracy_score_raw', xlabel='Neighbor Count (k)', ylabel = 'Accuracy Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that the best number to use for K is simply 1. Let's look at a few more helpful evaluation metrics for our single neighbor model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = knn(n_neighbors = 1) #we are creating a knn object and we set the number of neighbours equal to 1.\n",
    "knn_model.fit(x_train, y_train) #.fit would know what to do i.e. apply the best solution depending on what object we use. i.e. it will fit a knn algorithm\n",
    "\n",
    "test_predictions = knn_model.predict(x_test) #the predict command helps us make predictions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "\n",
    "#Code for confusion matrix with raw counts\n",
    "cm = confusion_matrix(y_test, test_predictions, labels=knn_model.classes_) #this confusion matrix needs the ... then we take our predictions and then we specify that classes we need.\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=knn_model.classes_)\n",
    "disp.plot(cmap='cividis')\n",
    "plt.title('Confusion Matrix of Observation Counts')\n",
    "plt.show()\n",
    "\n",
    "#Code for confusion matrix with proportions\n",
    "cm = confusion_matrix(y_test, test_predictions, labels=knn_model.classes_,normalize='all')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=knn_model.classes_)\n",
    "disp.plot(cmap='cividis')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the closest neighbors for our test dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = knn_model.kneighbors(x_test, n_neighbors = 1)\n",
    "idxs = list(neighbors[1].flatten())\n",
    "closest_n = x_train.iloc[idxs,]\n",
    "\n",
    "eval_df = x_test.copy()\n",
    "eval_df['closest_neighbor_idx'] = closest_n.index\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_option(\"display.max_columns\")\n",
    "\n",
    "display(bigfive_df.loc[[98,10],['Q1','Q14','Q24','Q34','Q45','Q9','Q19','Q29','Q39','Q50', 'is_extroverted']])\n",
    "display(bigfive_df.loc[[48,87],['Q1','Q14','Q24','Q34','Q45','Q9','Q19','Q29','Q39','Q50', 'is_extroverted']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll try to evaluate some other classification models, but since it will be the same process for the other models, we will also write a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC #i.e. Support Vector Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees\n",
    "clf = DecisionTreeClassifier(max_depth = 3, random_state = 42) #max_depth --> the max number of tree is allowed to have. random_state--> you specify a random state\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.predict(x_test))\n",
    "\n",
    "tree.export_graphviz(clf, out_file=\"tree.dot\",feature_names = x_train.columns,filled = True, proportion = True, class_names = ['Introverted','Extroverted'], leaves_parallel = True)\n",
    "\n",
    "display(pd.DataFrame(y_train).value_counts())\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_big5model(data, model, test_size = 0.2, normalize_cf = False, prediction_data = None):\n",
    "    if model not in  ['knn','randomforest','boost','svm','decisiontree']:\n",
    "        raise ValueError('Model {} not recognized. Model must be one of the following: {}'.format(model, ['knn','randomforest','boost','svm','decisiontree']))\n",
    "#with that function, we can run evaluations with one line (see ln[12])  \n",
    "\n",
    "    features = data.loc[:,'Q1':'Q54']\n",
    "    target = data['is_extroverted']\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = test_size, random_state = 42)\n",
    "    \n",
    "    init_model = None\n",
    "    \n",
    "    if model == 'knn':\n",
    "        init_model = knn(n_neighbors = 1)\n",
    "    elif model == 'randomforest':\n",
    "        init_model = RandomForestClassifier()\n",
    "    elif model == 'boost':\n",
    "        init_model = GradientBoostingClassifier()\n",
    "    elif model == 'svm':\n",
    "        init_model = SVC()\n",
    "    elif model == 'decisiontree':\n",
    "        init_model = DecisionTreeClassifier()\n",
    "        \n",
    "    fitted_model = init_model.fit(x_train ,y_train)\n",
    "    test_predictions = fitted_model.predict(x_test)\n",
    "    accuracy_score = fitted_model.score(x_test,y_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, test_predictions, labels=fitted_model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=fitted_model.classes_)\n",
    "    disp.plot(cmap='cividis')\n",
    "    plt.title('Confusion Matrix of Observation Counts for {}'.format(model))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Accuracy Score for {}: {:.2%}\".format(model, accuracy_score))\n",
    "    \n",
    "    if isinstance(prediction_data, type(None)) == False:\n",
    "        alex_features = prediction_data.loc[:,'Q1':'Q54']\n",
    "        alex_target = prediction_data['is_extroverted']\n",
    "        print('Alex Extroversion Prediction: {}'.format('Not Extroverted' if fitted_model.predict(alex_features)[0] == 0 else 'Extroverted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_big5model(bigfive_df, model='knn', prediction_data = alex_df)\n",
    "evaluate_big5model(bigfive_df, model='decisiontree', prediction_data = alex_df)\n",
    "evaluate_big5model(bigfive_df, model='randomforest', prediction_data = alex_df)\n",
    "evaluate_big5model(bigfive_df, model='boost', prediction_data = alex_df)\n",
    "evaluate_big5model(bigfive_df, model='svm', prediction_data = alex_df)\n",
    "\n",
    "#decision tree and random forest happen to generate the same prediction here. Based on the info we have we choose decision trees instead of random forests because its simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
