{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6af26f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'spotifyid.ipynb.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/utils/path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[0;34m(name, force_win32)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File `%r` not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File `'spotifyid.ipynb.py'` not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/71/m9n1tm292gg25xn0m44ccvxh0000gn/T/ipykernel_43226/2653803218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spotifyid.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mclient_credentials_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpotifyClientCredentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2349\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^'.*'$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: File `'spotifyid.ipynb.py'` not found."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import spotipy\n",
    "import pandas as pd\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "import graphviz\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%run spotifyid.ipynb\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Shows all the rows in all dataframes for make it easy for us to interpret the data when needed\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699adcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id=['0pa8KiIgQTFEtjJav6Ff6V','4h6xWeM4scivbL50bWnnZr',\n",
    "            '1CePBpYNwRCepOXyyavY5G','6xtrjdlqoxerdY1qwMHZIF',\n",
    "            '01uTFdq3G0PbFvE4JIVN5d','02Bg2havRnk0iHBpMg6alV',\n",
    "            '3Pof9oBfkSaB1rcF4FgH6n','1uM5YSTQhzM1rz5kyGYdnl',\n",
    "            '2XBusKFVE2RxdXk4vS1BbX','67yMmf3QuGUuBPd8YS6I3C',\n",
    "            '2AQTvUjTN76igRPTgSYknp','5uQtT3Nek57pDk33TEV2Ui',\n",
    "            '5bpUZJ42je385zdw18IKSI','5VP0JiOi2mls1ni1Q9qHEZ',\n",
    "            '5NnpIERkeDK0JmYnhSsL7N','3uN1VDvtpZw9AyGuW1Nh1p']\n",
    "\n",
    "df = []\n",
    "\n",
    "\n",
    "for idid in playlist_id:\n",
    "    results = sp.playlist(idid)\n",
    "    \n",
    "    playlist_name = results['name']\n",
    "    \n",
    "    id_list=[]\n",
    "\n",
    "    for item in results['tracks']['items']:\n",
    "        try:\n",
    "            track = item['track']['id']\n",
    "            id_list.append(track)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    song_meta={\n",
    "        'id':[],\n",
    "        'album':[], \n",
    "        'name':[], \n",
    "        'artist':[],\n",
    "        'explicit':[],\n",
    "        'popularity':[]\n",
    "    }\n",
    "\n",
    "    for song_id in id_list:\n",
    "        # get song's meta data\n",
    "        meta = sp.track(song_id)\n",
    "\n",
    "        # song id\n",
    "        song_meta['id'].append(song_id)\n",
    "\n",
    "        # album name\n",
    "        album=meta['album']['name']\n",
    "        song_meta['album']+=[album]\n",
    "\n",
    "        # song name\n",
    "        song=meta['name']\n",
    "        song_meta['name']+=[song]\n",
    "\n",
    "        # artists name\n",
    "        s = ', '\n",
    "        artist=s.join([singer_name['name'] for singer_name in meta['artists']])\n",
    "        song_meta['artist']+=[artist]\n",
    "\n",
    "        # explicit: lyrics could be considered offensive or unsuitable for children\n",
    "        explicit=meta['explicit']\n",
    "        song_meta['explicit'].append(explicit)\n",
    "\n",
    "        # song popularity\n",
    "        popularity=meta['popularity']\n",
    "        song_meta['popularity'].append(popularity)\n",
    "        \n",
    "\n",
    "    song_meta_df=pd.DataFrame.from_dict(song_meta)\n",
    "\n",
    "    # check the song feature\n",
    "    features = sp.audio_features(song_meta['id'])\n",
    "    # change dictionary to dataframe\n",
    "    features_df=pd.DataFrame.from_dict(features)\n",
    "\n",
    "    # convert milliseconds to mins\n",
    "    # duration_ms: The duration of the track in milliseconds.\n",
    "    # 1 minute = 60 seconds = 60 × 1000 milliseconds = 60,000 ms\n",
    "    features_df['duration_ms']=features_df['duration_ms']/60000\n",
    "\n",
    "    # combine two dataframe\n",
    "    final_df=song_meta_df.merge(features_df)\n",
    "    final_df['playlist_name'] = playlist_name\n",
    "    \n",
    "    df.append(final_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549becb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.concat(df)\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb422ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['playlist_name'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variable for 'explicit' column\n",
    "\n",
    "df_dummies = pd.get_dummies(df_agg, columns = ['explicit'])\n",
    "\n",
    "# Rename duration from milleseconds to seconds \n",
    "\n",
    "df_dummies.rename(columns = {'duration_ms': 'duration_s'}, inplace = True)\n",
    "\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the name of 2022 songs for future references\n",
    "\n",
    "songs_2022 = df_dummies.loc[:,'name':'artist'].iloc[1000:]\n",
    "\n",
    "#Drop 'id', 'uri', 'track_href', 'analysis_url', 'explicit_False' columns\n",
    "\n",
    "df_dummies.drop(['id','uri','track_href','analysis_url','explicit_False','album', 'name', 'artist','type'], inplace=True, axis=1)\n",
    "display(df_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35463e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into two data frames - one for the model, the other for the prediction data \n",
    "\n",
    "model_data = df_dummies.iloc[:999]\n",
    "predict_data = df_dummies.iloc[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6835903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column indicating whether the track is a Top 50 song or not\n",
    "\n",
    "model_data['top_50'] = pd.np.where(model_data['playlist_name'].str.contains(\"Not\"), 0,1)\n",
    "display(model_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 'playlist_name' column\n",
    "\n",
    "model_data.drop(['playlist_name'], inplace=True, axis=1)\n",
    "predict_data.drop(['playlist_name'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4690b",
   "metadata": {},
   "source": [
    "df_dummies --> cleaned data with top 50, not top 50, and test songs (in total 1100 songs)\n",
    "model_data --> includes top 50 and not top 50 (in total 1000 songs)\n",
    "predict_data --> includes tests songs we will test on prediction model data (in total 100 songs)\n",
    "\n",
    "#excel\n",
    "\n",
    "#model_data.to_excel(\"spotify.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670ad58",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we identify the top 50 songs from the complete dataframe\n",
    "top50playlists = model_data.iloc[:499]\n",
    "print(top50playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1e062",
   "metadata": {},
   "source": [
    "When your data has different values, and even different measurement units, it can be difficult to compare them. What is kilograms compared to meters? Or altitude compared to time?\n",
    "The answer to this problem is *scaling*. **We can scale data into new values that are easier to compare.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "#Scale all dataframe values (in the green colored brackets)\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "df = top50playlists\n",
    "\n",
    "X = df[['popularity', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "       'duration_s']]\n",
    "\n",
    "scaletop50 = scale.fit_transform(X)\n",
    "\n",
    "print(scaletop50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#elbow method to determine the correct number of clusters\n",
    "distortions = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(scaletop50)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdec63f",
   "metadata": {},
   "source": [
    "We use 6 clusters because the elbow's steepness flattens from that point onwards. In other words, for every cluster added after the 6th, the similarity is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "kmeans = KMeans(8) #k=8 means that we want 8 clusters of data\n",
    "kfit = kmeans.fit(scaletop50)\n",
    "identified_clusters = kfit.predict(scaletop50)\n",
    "print(kfit)\n",
    "print(identified_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I attach the clustering based on scaled data to the actual dataset (new column added)\n",
    "top50playlists['cluster'] = identified_clusters\n",
    "display(top50playlists)\n",
    "#IN THE DATAFRAME, THE LAST COLUMN 'CLUSTERS' IS INCORPORATED."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7af1c",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will work with all features but 'popularity'\n",
    "\n",
    "predict_data_new=predict_data.loc[:, predict_data.columns != 'popularity']\n",
    "display(predict_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction model\n",
    "\n",
    "# Dictionary for accuracy scores\n",
    "score_dict = {\n",
    "    'knn' : [],\n",
    "    'randomforest' : [],\n",
    "    'boost' : [],\n",
    "    'svm' : [],\n",
    "    'decisiontree' : [], \n",
    "    'logisticregression' : [],\n",
    "    'bag' : [],\n",
    "    'passiveaggressive' : [],\n",
    "    'radiusneighbors' : []\n",
    "}\n",
    "\n",
    "predict_dict = {\n",
    "    'knn' : [],\n",
    "    'randomforest' : [],\n",
    "    'boost' : [],\n",
    "    'svm' : [],\n",
    "    'decisiontree' : [], \n",
    "    'logisticregression' : [],\n",
    "    'bag' : [],\n",
    "    'passiveaggressive' : [],\n",
    "    'radiusneighbors' : []\n",
    "}\n",
    "\n",
    "importance_dict = {\n",
    "    'randomforest' : [],\n",
    "    'boost' : [],\n",
    "    'decisiontree' : [], \n",
    "}\n",
    "\n",
    "# Iterate multiple times\n",
    "n_iter = 100\n",
    "\n",
    "def evaluate_top(data_features, model, test_size = 0.2, normalize_cf = False, prediction_data = None):\n",
    "    for i in range(n_iter):\n",
    "        if model not in  ['knn','randomforest','boost','svm','decisiontree','logisticregression', 'bag', 'passiveaggressive','radiusneighbors']:\n",
    "            raise ValueError('Model {} not recognized. Model must be one of the following: {}'.format(model, ['knn','randomforest','boost','svm','decisiontree', 'logisticregression', 'bag', 'passiveaggressive','radiusneighbors']))\n",
    "     \n",
    "        #Split the data\n",
    "        data_features = model_data.loc[:,'danceability':'explicit_True']\n",
    "        data_target = model_data['top_50']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data_features,data_target, test_size = 0.2)\n",
    "\n",
    "        # Scale the data with minmax scalers | define min max scaler\n",
    "        scaler = MinMaxScaler()\n",
    "        # transform data\n",
    "        x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "        init_model = None\n",
    "\n",
    "        if model == 'knn':\n",
    "            init_model = knn(n_neighbors = 1)\n",
    "        elif model == 'randomforest':\n",
    "            init_model = RandomForestClassifier()\n",
    "        elif model == 'boost':\n",
    "            init_model = GradientBoostingClassifier()\n",
    "        elif model == 'svm': \n",
    "            init_model = SVC()\n",
    "        elif model == 'decisiontree': \n",
    "            init_model = DecisionTreeClassifier()\n",
    "        elif model == 'logisticregression':\n",
    "            init_model = LogisticRegression()\n",
    "        elif model == 'bag':\n",
    "            init_model = BaggingClassifier()\n",
    "        elif model == 'passiveaggressive':\n",
    "            init_model = PassiveAggressiveClassifier()\n",
    "        elif model == 'radiusneighbors':\n",
    "            init_model = RadiusNeighborsClassifier(outlier_label = \"most_frequent\")\n",
    "\n",
    "\n",
    "        fitted_model = init_model.fit(x_train_scaled ,y_train)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "        test_predictions = fitted_model.predict(x_test_scaled)\n",
    "        accuracy_score = fitted_model.score(x_test_scaled,y_test)\n",
    "        \n",
    "        # Accuracy Dictionary\n",
    "        score_dict[model].append(accuracy_score)\n",
    "        \n",
    "        # Feature importance Dictionary\n",
    "        if model in  ['randomforest','boost','decisiontree']:\n",
    "            feature_importance=fitted_model.feature_importances_\n",
    "            importance_dict[model].append(feature_importance)\n",
    "\n",
    "        cm = confusion_matrix(y_test, test_predictions, labels=fitted_model.classes_)\n",
    "        \n",
    "        # New data (2022 songs) scaled & predictions\n",
    "        if isinstance(prediction_data, type(None)) == False:    \n",
    "            predict_data_scaled = scaler.transform(predict_data_new)\n",
    "            predict_data_prediction = fitted_model.predict(predict_data_scaled)\n",
    "            predict_dict[model].append(predict_data_prediction) \n",
    "        \n",
    "        # NOTE: I'M NOT PRINTING THE CONFUSION MATRIX BECAUSE WE WOULD HAVE 100 FOR EACH MODEL, WHAT DO YOU THINK?\n",
    "        #disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=fitted_model.classes_)\n",
    "        #disp.plot(cmap='cividis')\n",
    "        #plt.title('Confusion Matrix of Observation Counts for {}'.format(model))\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "\n",
    "evaluate_top(model_data, model='decisiontree', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='logisticregression', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='knn', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='randomforest', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='boost', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='svm', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='bag', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='passiveaggressive', prediction_data = predict_data_new)\n",
    "evaluate_top(model_data, model='radiusneighbors', prediction_data = predict_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0299e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy from the 100 iterations\n",
    "\n",
    "model=['knn','randomforest','boost','svm','decisiontree','logisticregression', 'bag', 'passiveaggressive','radiusneighbors']\n",
    "interval=[]\n",
    "mean_accuracy=[]\n",
    "for i in model:\n",
    "    #Sort accuracy and select scores for the ~95% interval\n",
    "    sort=sorted(score_dict[i])\n",
    "    intervals=sort[2],sort[98]\n",
    "    interval.append(intervals)\n",
    "\n",
    "    #Mean accuracy for the 100 iterations\n",
    "    mean_acc = np.mean(score_dict[i])\n",
    "    mean_accuracy.append(mean_acc)\n",
    "\n",
    "accuracy = [f'{i*100:.2f}%' for i in mean_accuracy]\n",
    "CI_df = pd.DataFrame({'Model' : model, '95% CI' : interval, 'Mean accuracy':accuracy})\n",
    "display(CI_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with the model with the best accuracy: Random forest (1 Yes, 0 No)\n",
    "\n",
    "predictions=predict_dict['randomforest'][0]\n",
    "predictiondf = pd.DataFrame({'2022_Songs':songs_2022['name'],'Artist':songs_2022['artist'], 'Top50?':predictions})\n",
    "display(predictiondf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE DISPLAYING DATAFRAME IN CASE IS NEEDED FOR INTERPRETATIONS, IF NOT I RECOMMEND NOT DISPLAYING IT\n",
    "# Feature Relevance\n",
    "\n",
    "attributes=predict_data_new.columns.values.tolist()\n",
    "importance=importance_dict['randomforest'][2]\n",
    "pd.to_numeric(importance)\n",
    "importancedf = pd.DataFrame({'Features':attributes,'Relevance':importance})\n",
    "df_sorted_desc= importancedf.sort_values('Relevance',ascending=False)\n",
    "display(df_sorted_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature relevance\n",
    "\n",
    "df_sorted_desc.plot.bar(x=\"Features\", y=\"Relevance\", title='Feature Relevance')\n",
    "plt.gca().set_yticklabels([f'{x:.0%}' for x in plt.gca().get_yticks()]) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
