{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c9608f",
   "metadata": {},
   "source": [
    "With this code, any text from the internet can be analysed. Specifically, we can see which words are the most popular in the text inserted in cell \"[31]\". We can replace the Moby Dick's text with any other text, and see the most popular words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a262bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start as always with importing the necessary libraries\n",
    "\n",
    "import requests #PACKAGE THAT allows us download texts from online (e.g. I request Moby Dick's online book without downloading it)\n",
    "from bs4 import BeautifulSoup #Submodule of bs4 (I don't need the entire package). \n",
    "import nltk #natural language processing (NLP)\n",
    "from collections import Counter #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf031e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\r\n",
      "\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\">\r\n",
      "<head>\r\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\" />\r\n",
      "<meta http-equiv=\"Content-Style-Type\" content=\"text/css\" />\r\n",
      "<title>The Project Gutenberg eBook of Moby Dick; Or the Whale, by Herman Melville</title>\r\n",
      "\r\n",
      "<style type=\"text/css\" xml:space=\"preserve\">\r\n",
      "\r\n",
      "    body {margin-left:15%; margin-right:15%; text-align:justify }\r\n",
      "    p { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\r\n",
      "    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\r\n",
      "    hr  { width: 50%; text-align: center;}\r\n",
      "    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\r\n",
      "    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\r\n",
      "    .toc       { margin-left: 10%; margin-bottom: .75em;}\r\n",
      "    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\r\n",
      "\r\n",
      "    table      {margin-left: 10%;}\r\n",
      "\r\n",
      "a:link {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "link {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "a:visited {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "a:hover {color:red}\r\n",
      "\r\n",
      "</style>\r\n",
      "  </head>\r\n",
      "  <body>\r\n",
      "\r\n",
      "<div style='text-align:center; font-size:1.2em; font-weight:bold;'>The Project Gutenberg eBook of Moby-Dick; or The Whale, by Herman Melville</div>\r\n",
      "<div style='display:block; margin:1em 0'>\r\n",
      "This eBook is for the use of anyone anywhere in the United States and\r\n",
      "most other parts of the world at no cost and with almost no restrictions\r\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
      "of the Project Gutenberg License included with this eBook or online\r\n",
      "at <a href=\"https://www.gutenberg.org\">www.gutenberg.org</a>. If you\r\n",
      "are not located in the United States, you will have to check the laws of the\r\n",
      "country where you are located before using this eBoo\n"
     ]
    }
   ],
   "source": [
    "# We can now download the book that we want\n",
    "#https://www.gutenberg.org/files/2701/2701-h/2701-h.htm\n",
    "\n",
    "r = requests.get(\"https://www.gutenberg.org/files/2701/2701-h/2701-h.htm\") #that is how I get the book here without download it or saving it anywhere. I name it as r though to save it here.\n",
    "r.encoding = 'utf-8'#we use that to allow space for other characters in the text (other than the british alphabet letters)\n",
    "html = r.text #take the text of r, and save it as html\n",
    "print(html[0:2000]) #print the first 2000 characters of that html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1467b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Project Gutenberg eBook of Moby Dick; Or the Whale, by Herman Melville\n",
      "\n",
      "\n",
      "\n",
      "The Project Gutenberg eBook of Moby-Dick; or The Whale, by Herman Melville\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere in the United States and\r\n",
      "most other parts of the world at no cost and with almost no restrictions\r\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
      "of the Project Gutenberg License included with this eBook or online\r\n",
      "at www.gutenberg.org. If you\r\n",
      "are not located in the United States, you will have to check the laws of the\r\n",
      "country where you are located before using this eBook.\r\n",
      "\n",
      "Title: Moby-Dick; or The Whale\n",
      "Author: Herman Melville\n",
      "Release Date: June, 2001 [eBook #2701]\r\n",
      "[Most recently updated: August 18, 2021]\n",
      "Language: English\n",
      "Character set encoding: UTF-8\n",
      "Produced by: Daniel Lazarus, Jonesey, and David Widger\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK MOBY-DICK; OR THE WHALE ***\n",
      "\r\n",
      "      MOBY-DICK;or, THE WHALE.\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "      By Herman Melville\r\n",
      "    \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "CONTENTS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ETYMOLOGY. \n",
      "\n",
      "\n",
      " EXTRACTS (Supplied by a Sub-Sub-Librarian).\r\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " CHAPTER 1. Loomings. \n",
      "\n",
      "\n",
      " CHAPTER 2. The Carpet-Bag. \n",
      "\n",
      "\n",
      " CHAPTER 3. The Spouter-Inn. \n",
      "\n",
      "\n",
      " CHAPTER 4. The Counterpane. \n",
      "\n",
      "\n",
      " CHAPTER 5. Breakfast. \n",
      "\n",
      "\n",
      " CHAPTER 6. The Street. \n",
      "\n",
      "\n",
      " CHAPTER 7. The Chapel. \n",
      "\n",
      "\n",
      " CHAPTER 8. The Pulpit. \n",
      "\n",
      "\n",
      " CHAPTER 9. The Sermon. \n",
      "\n",
      "\n",
      " CHAPTER 10. A Bosom Friend. \n",
      "\n",
      "\n",
      " CHAPTER 11. Nightgown. \n",
      "\n",
      "\n",
      " CHAPTER 12. Biographical. \n",
      "\n",
      "\n",
      " CHAPTER 13. Wheelbarrow. \n",
      "\n",
      "\n",
      " CHAPTER 14. Nantucket. \n",
      "\n",
      "\n",
      " CHAPTER 15. Chowder. \n",
      "\n",
      "\n",
      " CHAPTER 16. The Ship. \n",
      "\n",
      "\n",
      " CHAPTER 17. The Ramadan. \n",
      "\n",
      "\n",
      " CHAPTER 18. His Mark. \n",
      "\n",
      "\n",
      " CHAPTER 19. The Prophet. \n",
      "\n",
      "\n",
      " CHAPTER 20. All Astir. \n",
      "\n",
      "\n",
      " CHAPTER 21. Going Aboard. \n",
      "\n",
      "\n",
      " CHAPTER 22. Merry Christmas. \n",
      "\n",
      "\n",
      " CHAPTER 23. The Lee Shore. \n",
      "\n",
      "\n",
      " CHAPTER 24. The Advocate. \n",
      "\n",
      "\n",
      " CHAPTER 25. Postscript. \n",
      "\n",
      "\n",
      " CHAPTER 26. Knights and Squires. \n",
      "\n",
      "\n",
      " CHAPTER 27. Knights and Squires. \n",
      "\n",
      "\n",
      " CHAPTER 28. Ahab. \n",
      "\n",
      "\n",
      " CHAPTER 29. Enter Ahab; to Him, Stubb. \n",
      "\n",
      "\n",
      " CHAPTER 30. The Pipe. \n",
      "\n",
      "\n",
      " CHAPTER 31. Queen Mab. \n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# We can now extract the useful data from it\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\") #I initiate an instance of BeautifulSoup, and I am working with html, and I need a parser which will allow me to separate the structure of the document\n",
    "text = soup.get_text() #take the soup, and get text from it\n",
    "print(text[0:2000])#again I use the print command to print the first 2000 characters of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a570394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Moby', 'Dick', 'Or']\n"
     ]
    }
   ],
   "source": [
    "# The document needs to be tokenized to be analyzed\n",
    "#we need to remove not useful words (e.g. \"the\")\n",
    "#also remove caps, dots, spaces, etc\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')#initiate an instance of nltk. We tokenize the document. RegexpTokenizer allows us to work with regular expressions(=ways to systematize words--e.g. is it a number, letter, punctuation etc)\n",
    "tokens = tokenizer.tokenize(text) #we need to remove punctuation.\n",
    "print(tokens[0:8]) #we print the first eight tokens (i.e. the words that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4422c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Some additional pre-processing is needed\n",
    "words = [token.lower() for token in tokens]#I lower from tokens, caps to lower letters\n",
    "print(words[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ba1390d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']\n"
     ]
    }
   ],
   "source": [
    "sw = nltk.corpus.stopwords.words('english')#(corpus includes dictionaries) we define our list of stopwords. We compare the text with the other text, and we remove those stopwords.\n",
    "print(sw[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d4506c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'moby', 'dick']\n"
     ]
    }
   ],
   "source": [
    "words_ns = [word for word in words if word not in sw]#each individual element of words is going to be called 'word'.Scroll through all the words in the list, look at every element of the list, keep the word, and list it only if the word is not a stopword.\n",
    "print(words_ns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4cec289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whale', 1244), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"
     ]
    }
   ],
   "source": [
    "# We can now analyze the data and determine the most common word\n",
    "count = Counter(words_ns)\n",
    "top_ten = count.most_common(10)\n",
    "print(top_ten)#most common word is 'whale', then 'one', etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "911d6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can just replace the link with another link, and see which is the most commonly used word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c15a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
